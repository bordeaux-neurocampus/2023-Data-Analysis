{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fMRI mini project - Time_Frequency analysis for resting state maps\n",
    "In this project, we will work on fMRI data from the  Amsterdam Open MRI Collection (AOMIC).\n",
    "\n",
    "The AOMIC dataset gathers MRI data from more than a thousand individuals obtained on a 3 Tesla imager. For each subject we can access the T1-weighted images ( anatomical image), the diffusion-weighted images ( white-matter tracts)  and fMRI sequences (task-based and resting states). The dataset gives access to both raw and preprocessed (derivative) data. The description of the data acquisition and processing is available here : \n",
    "\n",
    "**Snoek, L., van der Miesen, M. M., Beemsterboer, T., Van Der Leij, A., Eigenhuis, A., & Scholte, H. S. (2021). The Amsterdam Open MRI Collection, a set of multimodal MRI datasets for individual difference analyses. Scientific data, 8(1), 1-23.**\n",
    "\n",
    "All data are publicly available for downloads using AWS s3 buckets s3://openneuro.org/. The projects will use Jupyter Notebook with the following library : numpy, scipy,  scikit-learn; nilearn.\n",
    "\n",
    "We will use time-frequency analysis to propose connectivity map in resting-state and compared with the RSN proposed in the paper :   **Smith, SM, Fox, PT, Miller, KL, Glahn, DC, Fox, PM, Mackay, CE, Filippini, N, Watkins, KE, Toro, R, Laird, AR, Beckmann, CF (2009). Correspondence of the brain's functional architecture during activation and rest. Proc Natl Acad Sci U S A, 106, 31:13040-5.**\n",
    "\n",
    "\n",
    "The AOMIC dataset is avalable for download as S3 bucket. We will use the boto3 package to search and download the elemts we need.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pip command, install boto lpackage if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all nedded package and instanciate a boto client for s3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the S3 bucket is \"openneuro.org', and all objects in buckets have \"prefix\". In our case it correspond to the path of the object in a [BIDS](https://bids-specification.readthedocs.io/en/stable/index.html) standard.\n",
    "\n",
    "PIOP1 cohort has in prefix that starts with ds002785 \n",
    "\n",
    " and preprocessed data are in /derivatives folder We will get  get all the task working memory fmri files for  individual sub-001\n",
    "\n",
    "Define the full prefix then you can use *paginator* to research 'task-workingmemory' in the files.\n",
    " 00\n",
    "and a (list) generator with the syntax  [operation_on_key for key in list] \n",
    "to retrive the \"Key\" field on the selected objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpXFfE2apj5c"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "# Loading Resting State images found on AOMIC for ind 0001\n",
    "##########################################################\n",
    "\n",
    "# 1 - Filter the data to include resting state only\n",
    "\n",
    "paginator = client.get_paginator('list_objects')\n",
    "\n",
    "operation_parameters = ...\n",
    "\n",
    "result = paginator.paginate(**operation_parameters)\n",
    "filtered_iterator = result.search(\"Contents[?Key.contains(@,'task-restingstate')]\")\n",
    "task_list=[key_data['Key'] for key_data in filtered_iterator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyRRWdTVqove"
   },
   "outputs": [],
   "source": [
    "# 2 - Use Panda library to select our files\n",
    "import pandas as pd\n",
    "# make an np array from tak list\n",
    "files=...\n",
    "# split the filenames with the \"/\" character  \n",
    "filename_split = ..\n",
    "# the filenames are all in the 6 elements, cast last object as pd.dataFrame to get it \n",
    "pd_filename_list=  ...\n",
    "# make another dataframe by splitting the filenames with the \"_\" character and print it\n",
    "....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now list all the nii.gz files\n",
    "\n",
    "we  can use 'endwith' function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_task=...\n",
    "# make an np.array of the sekected filenames\n",
    "nii_files=...\n",
    "# make a panda dataframe by splitting the filenames with the \"_\" character and print it\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select the key for preprocessed  frmi volumes in MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_key = nii_files[...]  # choose the file you want in nii_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the boto3 client to download the file\n",
    "# save it to \"resting.nii.gz\"\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed install nilearn package with pip\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nilearn image library \n",
    "....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  read  image  .nii.gz with nilearn image library\n",
    "img=  ...\n",
    "#  always chack and print the dimension of the data\n",
    "print(img .... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we going to compute the mean (average) image usinng numpy\n",
    "# you need to import the numpy library\n",
    "import ...\n",
    "# find nilearn image function to compute average 3d volume of a fMRI sequence volume\n",
    "# compute average image using image library\n",
    "mean_img= ...\n",
    "# always check the dimension of the data \n",
    "print(.... ) \n",
    "# use the  triplanar interactive view of nilearn\n",
    "# to explore the average 3d volume\n",
    "... mean_img ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to ectract all the data and plot them separately either as 2d image eaither aas time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# extract 4D array from nilear image object\n",
    "volume= ....\n",
    "# check the dimension of the data \n",
    "print (volume.shape)\n",
    "# eextract one slice (2D image)\n",
    "flat_slice=volume..... \n",
    "# check thye size\n",
    "print (flat_slice.shape)\n",
    "# use matplotlib imshow to plot the slice  \n",
    "plt.imshow(flat_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the time serie for one voxel \n",
    "ts=volume ....\n",
    "# in the AOMICS website find repeat tim RT RT : time in sec between 2 image in [s]  \n",
    "dt=...\n",
    "# make a vector of slice times in [s]  \n",
    "time_vec= ...# vector \n",
    "print(time_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7))\n",
    "ax1=plt.subplot(211)\n",
    "# plot the normalaized time serie\n",
    "plt.plot(... , label='bold signal at'+np.array2string(np.array([30,35,30])), linewidth=0.5)\n",
    "plt.ylabel('bold signal')\n",
    "plt.title('bold signal for 1 voxel')\n",
    "\n",
    "plt.subplot(212,  sharex = ax1)\n",
    "# plot the task events as stem of heigth  1\n",
    "plt.stem() \n",
    "# Add title and labels\n",
    "plt.ylabel('stop task events')\n",
    "plt.xlabel('time in [s]')\n",
    "# Add legend\n",
    "plt.legend()\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "# Display plot\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in the AOMICS website find which file is the segmentation file (the brain regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "KNlRSajVs23C",
    "outputId": "d5fd3360-d707-42c1-a774-c175b60d63d0"
   },
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "file_key= ... # find which image is the mask of regions \n",
    "# use the boto3 client to download the file\n",
    "# save it to  my.nii_seg.nii.gz\n",
    "...\n",
    "\n",
    "#  read  image my.nii_seg.nii.gz with nilear image library\n",
    "img_seg=  ...\n",
    "#  always chack and print the dimension of the data\n",
    "print(img_seg .... )\n",
    "# find the nilearn image function to plot regions\n",
    "...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will use the segmentation to create a mask of region to extract all the time series from one region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kj4PnXzns37A",
    "outputId": "f5d5497e-ac00-485f-f90a-b1b1a759f75e"
   },
   "outputs": [],
   "source": [
    "from nilearn.masking import apply_mask\n",
    "import nibabel as nb\n",
    "# extract the segmentation volume in a np.array \n",
    "img_segbool=np.array(..)\n",
    "# always check the size\n",
    "print(np.sum(img_segbool))\n",
    "# with np.where find the voxels of the region numbered 10 \n",
    "mask1=np.where(...)\n",
    "# now set all background to 0\n",
    "img_segbool....=0\n",
    "#  and set the voxels from the mask to 1\n",
    "img_segbool...=1\n",
    "\n",
    "\n",
    "#always check the size is right\n",
    "img_segbool.shape\n",
    "# count hozw many voxels in the region with np.sum\n",
    "np.sum(...)\n",
    "#  find how to make a proper nii volume from img_segbool \n",
    "#  using  Nifti1Image function and the original img_seg volume \n",
    "nii_img_seg=nb.Nifti1Image(....)\n",
    "# use the interactive region viewer to check your segmentation \n",
    ".....\n",
    "# find how to use apply_mask to retreive the timeseries of the selected region\n",
    "# using the original nii volume img and the region volume nii_img_seg\n",
    "masked_data = ....\n",
    "\n",
    "# check masked_data shape is (timepoints, voxels).\n",
    "masked_data...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "id": "X2GIaFPGs9Mi",
    "outputId": "3abfefb9-e2bf-4819-b481-9cc7def1f5bb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# And now plot two time series\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(masked_data[:, :2])\n",
    "plt.xlabel('Time [TRs]', fontsize=16)\n",
    "plt.ylabel('Intensity', fontsize=16)\n",
    "#plt.xlim(0, 150)\n",
    "plt.subplots_adjust(bottom=.12, top=.95, right=.95, left=.12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to process the time serie. \n",
    "First we need to load the scipy libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft,fftfreq\n",
    "from scipy.fftpack import fftshift\n",
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step  is removing complex signal drift\n",
    "For that we are fititng three degree polygone curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vboU2YtptAjZ"
   },
   "outputs": [],
   "source": [
    "### removing complex signal drift \n",
    "#choose a time serie as example : \n",
    "ts = ...\n",
    "# a / fit a 4 degree polynome -- or a low frequency cosine\n",
    "# for a polynome\n",
    "# find a0, a, b, c, d that fit the signal y= a0 + ax + bx² +cx³ +dx⁴\n",
    "# you can use the code used in the filtering exercice \n",
    "# with optimize.curve_fit and a test_func \n",
    "# or use numpy.polyfit\n",
    "# for low frequency cosine, use very low (<0.01) frequecy\n",
    "#for starting parameters optimize.curve_fit  \n",
    "\n",
    "drift = ....\n",
    "\n",
    "# b/ remove the fitted drift from the signa\n",
    "yf=ts-drift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the AOMICS website find repeat tim RT RT : time in sec between 2 image in [s]  \n",
    "dt=...\n",
    "# make a vector of slice times in [s]  \n",
    "time_vec= ...# vector \n",
    "print(time_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the whole process\n",
    "t = time_vec\n",
    "y=ts\n",
    "plt.figure(figsize=(14,10))\n",
    "\n",
    "# plot signal and the fitted drift\n",
    "ax2=plt.subplot(411)\n",
    "plt.plot(t, y, 'b-', label='signal')\n",
    "plt.plot(t,drift, 'g--', label='drift')\n",
    "plt.ylabel('bold signal')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# plot  sprectrogram for original signal \n",
    "freqs, times, spectro = spectrogram( y,fs=1/dt, nperseg=3)\n",
    "plt.subplot(412, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.legend()\n",
    "\n",
    "# plot old and new signal (centerd on the mean)\n",
    "plt.subplot(413, sharex=ax2)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, y-y.mean(), label='old bold signal', linewidth=0.5)\n",
    "plt.plot(np.array(range(0,len(ts)))*dt, yf-yf.mean(), label='new voxel bold signal', linewidth=2)\n",
    "plt.legend()\n",
    "\n",
    "# plot  sprectrogram for new signal \n",
    "freqs, times, spectro = spectrogram( yf,fs=1/dt, nperseg=3)\n",
    "plt.subplot(414, sharex=ax2)\n",
    "plt.pcolormesh(times, fftshift(freqs), fftshift(spectro, axes=0), shading='gouraud')\n",
    "plt.ylabel('f [Hz]')\n",
    "plt.xlabel('t [sec]')\n",
    "plt.legend()\n",
    "\n",
    "# Auto space\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make a high pass filter with the code use in the filtering exercice \n",
    "fc = 0.01  # desired cutoff frequency of the filter, Hz\n",
    "....\n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the original signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "...\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a low pass filter  with the code use in the filtering exercice\n",
    "fc = 0.15 \n",
    "# Plot the frequency response ( the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the original signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# apply the filter to the signal obtained after drift removal (the code use in the filtering exercice)\n",
    "...\n",
    "# plot both the original and filtered signals (the code use in the filtering exercice)\n",
    "...\n",
    "# calculate the FFT of the filtered signal and plot the frequency components (the code use in the filtering exercice)\n",
    "...\n",
    "# plot spectrogram (the code use in the previous cell )  before and after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repeat the filterinfg (drift + 2 filters) for another time serie\n",
    "# and propose a measure of correlation based ond frequecy specrtum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend to cross-region analysis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
